# Pipeline Configuration
# Data flow: data/ -> segmentation/output/ -> embedding/output/ -> detection/output/ -> output/

# Stage 1: Segmentation
segmentation:
  input_file: "/data/guyb/tibetan_data/Tibetan_1.jsonl"
  output_dir: "segmentation/output"
  engine: "regex"                 # "regex" (fast) or "botok" (accurate)
  min_syllables: 4
  use_overlapping: true
  overlap_max_atoms: 8
  overlap_min_chars: 8
  overlap_max_chars: 350
  max_spans_per_line: 300

# Stage 2: Embedding
embedding:
  input_dir: "segmentation/output/overlapping/Full_Files"
  output_dir: "embedding/output"
  model: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
  batch_size: 32
  device: "auto"
  mode: "per_line"
  text_column: "Segmented_Text"

# Stage 3: Detection
detection:
  data_dir: "embedding/output/embeddings_by_line"
  output_path: "detection/output/parallels.csv"
  threshold: 0.90
  batch_size: 1000
  strategy: "threshold"
  format: "csv"
  device: "auto"                    # "auto", "cuda", or "cpu"
  max_lines_per_file: 200000        # 0 = unlimited, single file
